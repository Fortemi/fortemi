# =============================================================================
# Matric Memory - Environment Variables
# =============================================================================
# Copy this file to .env and configure for your environment.
# Variables with values shown are defaults; commented variables are optional.
#
# For Docker bundle deployment, only the variables under "Docker Bundle" are
# needed. The compose file sets sensible defaults for everything else.
#
# For standalone (non-Docker) deployment, configure all sections as needed.

# =============================================================================
# Docker Bundle Deployment
# =============================================================================
# Image tag to pull (default: bundle-latest)
# FORTEMI_TAG=bundle-latest

# External URL (REQUIRED for OAuth, MCP authentication, and public-facing links)
# This URL appears in upload guidance, export links, and OAuth metadata.
# ISSUER_URL=https://memory.example.com

# Internal API URL for MCP server → API communication (default: http://localhost:3000)
# In the Docker bundle, MCP and API run in the same container, so localhost is correct.
# Only change this for split deployments where MCP and API are separate containers.
# FORTEMI_URL=http://localhost:3000

# MCP OAuth credentials for token introspection
# Auto-managed: The bundle entrypoint auto-registers an MCP OAuth client on startup
# if credentials are missing or invalid (e.g., after a clean deploy with `down -v`).
# Credentials are persisted on the pgdata volume and reused across restarts.
# You only need to set these manually for standalone (non-Docker) deployments.
# MCP_CLIENT_ID=mm_xxx
# MCP_CLIENT_SECRET=xxx

# =============================================================================
# Database
# =============================================================================
# For standalone deployment only (Docker bundle uses POSTGRES_* vars)
DATABASE_URL=postgres://matric:matric@localhost:5432/matric

# =============================================================================
# Authentication
# =============================================================================
# Set to true to require authentication on all /api/v1/* endpoints
# When false (default), all endpoints are publicly accessible
# REQUIRE_AUTH=false

# OAuth access token lifetime in seconds (default: 3600 = 1 hour)
# Shorter = more secure, longer = less re-authentication friction
# OAUTH_TOKEN_LIFETIME_SECS=3600

# MCP token lifetime in seconds (default: 14400 = 4 hours)
# MCP sessions are interactive — shorter tokens cause mid-session disconnects
# OAUTH_MCP_TOKEN_LIFETIME_SECS=14400

# =============================================================================
# API Server
# =============================================================================
HOST=0.0.0.0
PORT=3000
RUST_LOG=info

# CORS - comma-separated list of allowed origins
# ALLOWED_ORIGINS=https://memory.example.com,http://localhost:3000

# Maximum request body size in bytes (default: 2 GB, for database backups)
# MATRIC_MAX_BODY_SIZE_BYTES=2147483648

# =============================================================================
# Rate Limiting
# =============================================================================
# RATE_LIMIT_ENABLED=true
# RATE_LIMIT_REQUESTS=100
# RATE_LIMIT_PERIOD_SECS=60

# =============================================================================
# Logging
# =============================================================================
# LOG_FORMAT=json
# LOG_FILE=/var/log/matric/api.log
# LOG_ANSI=false

# =============================================================================
# Background Worker
# =============================================================================
# WORKER_ENABLED=true

# =============================================================================
# File Storage
# =============================================================================
# FILE_STORAGE_PATH=/var/lib/matric/files

# =============================================================================
# Real-Time Events
# =============================================================================
# MATRIC_EVENT_BUS_CAPACITY=256
# MATRIC_WEBHOOK_TIMEOUT_SECS=10

# =============================================================================
# Full-Text Search
# =============================================================================
# FTS_SCRIPT_DETECTION=true
# FTS_TRIGRAM_FALLBACK=true
# FTS_BIGRAM_CJK=true
# FTS_MULTILINGUAL_CONFIGS=true
# FTS_WEBSEARCH_TO_TSQUERY=true

# =============================================================================
# Redis Cache
# =============================================================================
# REDIS_ENABLED=true
# REDIS_URL=redis://localhost:6379
# REDIS_CACHE_TTL=300

# =============================================================================
# Backup
# =============================================================================
# BACKUP_DEST=/var/backups/matric-memory
# BACKUP_SCRIPT_PATH=/usr/local/bin/backup-matric.sh

# =============================================================================
# Inference Provider Selection
# =============================================================================
# MATRIC_INFERENCE_DEFAULT=ollama

# =============================================================================
# Ollama (local LLM)
# =============================================================================
# OLLAMA_BASE=http://localhost:11434
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_EMBED_MODEL=nomic-embed-text
# OLLAMA_GEN_MODEL=gpt-oss:20b
# OLLAMA_EMBED_DIM=768
# MATRIC_OLLAMA_URL=http://localhost:11434
# MATRIC_OLLAMA_EMBEDDING_MODEL=nomic-embed-text
# MATRIC_OLLAMA_GENERATION_MODEL=gpt-oss:20b
# MATRIC_EMBED_TIMEOUT_SECS=30
# MATRIC_GEN_TIMEOUT_SECS=120

# =============================================================================
# OpenAI (alternative to Ollama)
# =============================================================================
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_API_KEY=sk-xxx
# OPENAI_EMBED_MODEL=text-embedding-3-small
# OPENAI_GEN_MODEL=gpt-4o-mini
# OPENAI_EMBED_DIM=1536
# OPENAI_TIMEOUT=30
# OPENAI_SKIP_TLS_VERIFY=false
# OPENAI_HTTP_REFERER=https://memory.example.com
# OPENAI_X_TITLE=Matric Memory
# MATRIC_OPENAI_URL=https://api.openai.com/v1
# MATRIC_OPENAI_API_KEY=sk-xxx
# MATRIC_OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# MATRIC_OPENAI_GENERATION_MODEL=gpt-4o-mini

# =============================================================================
# Fast Model (extraction pipeline)
# =============================================================================
# Small model for concept tagging, reference extraction, and title generation.
# Default: granite4:3b (244 tok/s, 98K context). Set to empty to disable.
# Large documents are automatically chunked for the fast model.
# On failure, escalates to the standard model (OLLAMA_GEN_MODEL).
# MATRIC_FAST_GEN_MODEL=granite4:3b
# MATRIC_FAST_GEN_TIMEOUT_SECS=30

# =============================================================================
# Extraction Services (optional)
# =============================================================================
# Vision model for image extraction
# Requires Ollama with vision model pulled (e.g., qwen3-vl:8b)
# OLLAMA_VISION_MODEL=qwen3-vl:8b

# Whisper transcription service
# Deploy via docker-compose.whisper.yml
# WHISPER_BASE_URL=http://host.docker.internal:8000
# WHISPER_MODEL=Systran/faster-distil-whisper-large-v3

# OCR and document processing
# OCR_ENABLED=false
# LIBREOFFICE_PATH=/usr/bin/libreoffice

# =============================================================================
# Support Memory Archive
# =============================================================================
# The fortemi-docs archive ships with product documentation pre-indexed for
# semantic search. Set to true to disable automatic loading on first boot.
# DISABLE_SUPPORT_MEMORY=false

# =============================================================================
# Multi-Memory Architecture
# =============================================================================
# Maximum concurrent live memories (default: 10). Scale with hardware.
# MAX_MEMORIES=10

# =============================================================================
# MCP Server (standalone deployment)
# =============================================================================
# MCP_TRANSPORT=http
# MCP_PORT=3001
# MCP_BASE_URL=http://localhost:3000/mcp
# MCP_BASE_PATH=/mcp
# FORTEMI_URL=http://localhost:3000
# FORTEMI_API_KEY=
