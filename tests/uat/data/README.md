# UAT Test Data Package

Comprehensive test data for exercising all Fort√©mi capabilities including:
- Document type detection and chunking
- EXIF metadata extraction
- Multilingual full-text search
- W3C PROV provenance tracking
- Vision extraction (image description)
- Audio transcription
- Edge case handling

## Directory Structure

```
tests/uat/data/
‚îú‚îÄ‚îÄ README.md                          # This file
‚îú‚îÄ‚îÄ MANIFEST.md                        # Detailed file inventory
‚îú‚îÄ‚îÄ images/                            # Image files with metadata
‚îÇ   ‚îú‚îÄ‚îÄ jpeg-with-exif.jpg            # JPEG with full EXIF (GPS, camera, date)
‚îÇ   ‚îú‚îÄ‚îÄ jpeg-no-metadata.jpg          # JPEG stripped of metadata
‚îÇ   ‚îú‚îÄ‚îÄ png-transparent.png           # PNG with transparency
‚îÇ   ‚îú‚îÄ‚îÄ webp-modern.webp              # WebP for modern format support
‚îÇ   ‚îú‚îÄ‚îÄ faces-group-photo.jpg         # Image with human faces
‚îÇ   ‚îú‚îÄ‚îÄ object-scene.jpg              # Scene with recognizable objects
‚îÇ   ‚îî‚îÄ‚îÄ emoji-unicode-ÂêçÂâç.jpg         # Unicode filename edge case
‚îú‚îÄ‚îÄ documents/                         # Document files
‚îÇ   ‚îú‚îÄ‚îÄ pdf-single-page.pdf           # Simple 1-page PDF
‚îÇ   ‚îú‚îÄ‚îÄ pdf-multi-page.pdf            # Multi-page PDF with TOC
‚îÇ   ‚îú‚îÄ‚îÄ code-python.py                # Python code sample
‚îÇ   ‚îú‚îÄ‚îÄ code-rust.rs                  # Rust code sample
‚îÇ   ‚îú‚îÄ‚îÄ code-javascript.js            # JavaScript code sample
‚îÇ   ‚îú‚îÄ‚îÄ code-typescript.ts            # TypeScript code sample
‚îÇ   ‚îú‚îÄ‚îÄ markdown-formatted.md         # Markdown with various elements
‚îÇ   ‚îú‚îÄ‚îÄ json-config.json              # JSON configuration
‚îÇ   ‚îú‚îÄ‚îÄ yaml-config.yaml              # YAML configuration
‚îÇ   ‚îî‚îÄ‚îÄ csv-data.csv                  # CSV data file
‚îú‚îÄ‚îÄ audio/                             # Audio samples
‚îÇ   ‚îú‚îÄ‚îÄ english-speech-5s.mp3         # 5-second English speech
‚îÇ   ‚îú‚îÄ‚îÄ spanish-greeting.mp3          # Spanish language sample
‚îÇ   ‚îî‚îÄ‚îÄ chinese-phrase.mp3            # Chinese (Mandarin) sample
‚îú‚îÄ‚îÄ multilingual/                      # Multilingual text samples
‚îÇ   ‚îú‚îÄ‚îÄ english.txt                   # English text
‚îÇ   ‚îú‚îÄ‚îÄ german.txt                    # German text
‚îÇ   ‚îú‚îÄ‚îÄ french.txt                    # French text
‚îÇ   ‚îú‚îÄ‚îÄ spanish.txt                   # Spanish text
‚îÇ   ‚îú‚îÄ‚îÄ portuguese.txt                # Portuguese text
‚îÇ   ‚îú‚îÄ‚îÄ russian.txt                   # Russian text (Cyrillic)
‚îÇ   ‚îú‚îÄ‚îÄ chinese-simplified.txt        # Simplified Chinese (CJK)
‚îÇ   ‚îú‚îÄ‚îÄ japanese.txt                  # Japanese (CJK)
‚îÇ   ‚îú‚îÄ‚îÄ korean.txt                    # Korean (CJK)
‚îÇ   ‚îú‚îÄ‚îÄ arabic.txt                    # Arabic text
‚îÇ   ‚îú‚îÄ‚îÄ greek.txt                     # Greek text
‚îÇ   ‚îú‚îÄ‚îÄ hebrew.txt                    # Hebrew text
‚îÇ   ‚îî‚îÄ‚îÄ emoji-heavy.txt               # Text with many emoji
‚îú‚îÄ‚îÄ edge-cases/                        # Edge case test files
‚îÇ   ‚îú‚îÄ‚îÄ empty.txt                     # Empty file (0 bytes)
‚îÇ   ‚îú‚îÄ‚îÄ large-text-100kb.txt          # Large text file (>100KB)
‚îÇ   ‚îú‚îÄ‚îÄ binary-wrong-ext.jpg          # Binary file misnamed as image
‚îÇ   ‚îú‚îÄ‚îÄ unicode-filename-ÊµãËØï.txt      # Unicode in filename
‚îÇ   ‚îú‚îÄ‚îÄ whitespace-only.txt           # File with only whitespace
‚îÇ   ‚îî‚îÄ‚îÄ malformed-json.json           # JSON with syntax errors
‚îú‚îÄ‚îÄ provenance/                        # Files for provenance testing
‚îÇ   ‚îú‚îÄ‚îÄ paris-eiffel-tower.jpg        # GPS: Paris, France
‚îÇ   ‚îú‚îÄ‚îÄ newyork-statue-liberty.jpg    # GPS: New York, USA
‚îÇ   ‚îú‚îÄ‚îÄ tokyo-shibuya.jpg             # GPS: Tokyo, Japan
‚îÇ   ‚îú‚îÄ‚îÄ dated-2020-01-01.jpg          # Known timestamp: 2020-01-01
‚îÇ   ‚îú‚îÄ‚îÄ dated-2025-12-31.jpg          # Known timestamp: 2025-12-31
‚îÇ   ‚îú‚îÄ‚îÄ duplicate-content-1.txt       # Duplicate content test
‚îÇ   ‚îî‚îÄ‚îÄ duplicate-content-2.txt       # Same content, different file
‚îî‚îÄ‚îÄ scripts/                           # Generation scripts
    ‚îú‚îÄ‚îÄ generate-test-data.sh         # Main generation script
    ‚îú‚îÄ‚îÄ create-exif-images.py         # Python script for EXIF injection
    ‚îú‚îÄ‚îÄ generate-multilingual.py      # Generate multilingual samples
    ‚îî‚îÄ‚îÄ create-audio-samples.sh       # Generate audio samples
```

## File Specifications

See `MANIFEST.md` for detailed specifications of each test file including:
- Expected metadata
- File size
- Content description
- Expected extraction results
- Test scenarios

## Usage

### Quick Setup

Generate all synthetic test data:

```bash
cd tests/uat/data/scripts
./generate-test-data.sh
```

This will create all necessary test files in their respective directories.

### Individual Generation

Generate specific categories:

```bash
# Images with EXIF
python3 scripts/create-exif-images.py

# Multilingual text samples
python3 scripts/generate-multilingual.py

# Audio samples (requires ffmpeg)
./scripts/create-audio-samples.sh
```

### Download Pre-built Test Data

For convenience, pre-built test data is available:

```bash
# Download from release artifacts
wget https://github.com/fortemi/fortemi/releases/download/v2026.2.0/uat-test-data.tar.gz
tar -xzf uat-test-data.tar.gz -C tests/uat/data/
```

## Test Scenarios

### 1. Image Metadata Extraction

**Files**: `images/jpeg-with-exif.jpg`, `provenance/paris-eiffel-tower.jpg`

**Expected behavior**:
- Extract GPS coordinates and convert to PostGIS geography
- Extract camera make/model (e.g., "Apple iPhone 15 Pro")
- Extract capture datetime and convert to UTC
- Store as W3C PROV provenance data

**Verification**:
```bash
# Upload image
curl -X POST http://localhost:3000/api/v1/notes \
  -F "content=@images/jpeg-with-exif.jpg" \
  -F "tags=test,image"

# Check extracted metadata
curl http://localhost:3000/api/v1/notes/{note_id} | jq '.note.metadata'
```

### 2. Document Type Auto-Detection

**Files**: `documents/code-python.py`, `documents/markdown-formatted.md`

**Expected behavior**:
- Auto-detect document type from file extension and magic patterns
- Apply appropriate chunking strategy (syntactic for code, semantic for prose)
- Associate with document_type_id

**Verification**:
```sql
SELECT n.id, n.title, dt.name as document_type, dt.chunking_strategy
FROM note n
JOIN document_type dt ON n.document_type_id = dt.id
WHERE n.title LIKE '%python%';
```

### 3. Multilingual Full-Text Search

**Files**: `multilingual/*.txt`

**Expected behavior**:
- English/German/French/Spanish/Portuguese: Use stemming via `websearch_to_tsquery`
- CJK (Chinese/Japanese/Korean): Use bigram matching
- Arabic/Russian/Greek/Hebrew: Basic tokenization
- Emoji: Trigram substring matching

**Verification**:
```bash
# English stemming
curl "http://localhost:3000/api/v1/search?q=running&tags=test" # matches "run", "runs", "running"

# CJK bigram
curl "http://localhost:3000/api/v1/search?q=Êù±‰∫¨&tags=test" # matches Chinese/Japanese text

# Emoji search
curl "http://localhost:3000/api/v1/search?q=üéâ&tags=test" # matches emoji content
```

### 4. Provenance Tracking

**Files**: `provenance/paris-eiffel-tower.jpg`, `provenance/duplicate-content-*.txt`

**Expected behavior**:
- Track GPS coordinates as spatial provenance
- Track timestamps as temporal provenance
- Detect duplicate content via content hash
- Link related notes through provenance chains

**Verification**:
```sql
-- Check spatial provenance
SELECT n.id, n.title,
       ST_AsText(p.location_geography::geometry) as location,
       p.created_at_utc
FROM note n
JOIN provenance_edge p ON n.id = p.revision_id
WHERE p.location_geography IS NOT NULL;

-- Check duplicate content
SELECT hash, COUNT(*) as count
FROM note_original
GROUP BY hash
HAVING COUNT(*) > 1;
```

### 5. Edge Case Handling

**Files**: `edge-cases/*`

**Expected behavior**:
- Empty file: Accept but warn (no content to index)
- Large file (>100KB): Chunk appropriately based on document type
- Binary with wrong extension: Reject with clear error message
- Unicode filename: Store correctly without mojibake
- Whitespace-only: Accept but mark as empty content
- Malformed JSON: Store as plain text if JSON parsing fails

**Verification**:
```bash
# Empty file
curl -X POST http://localhost:3000/api/v1/notes \
  -F "content=@edge-cases/empty.txt" \
  -F "tags=test,edge-case"
# Expected: HTTP 200, warning in metadata

# Large file
curl -X POST http://localhost:3000/api/v1/notes \
  -F "content=@edge-cases/large-text-100kb.txt" \
  -F "tags=test,edge-case"
# Expected: HTTP 200, multiple chunks created

# Unicode filename
curl -X POST http://localhost:3000/api/v1/notes \
  -F "content=@edge-cases/unicode-filename-ÊµãËØï.txt" \
  -F "tags=test,unicode"
# Expected: HTTP 200, filename stored correctly
```

## Coverage Matrix

| Capability | Test Files | Expected Result |
|------------|------------|-----------------|
| **EXIF GPS extraction** | `images/jpeg-with-exif.jpg`, `provenance/paris-*.jpg` | PostGIS geography with coordinates |
| **EXIF datetime extraction** | `provenance/dated-*.jpg` | UTC timestamp in metadata |
| **EXIF camera info** | `images/jpeg-with-exif.jpg` | Device make/model in metadata |
| **Image without metadata** | `images/jpeg-no-metadata.jpg` | No EXIF metadata, file accepted |
| **Modern image formats** | `images/webp-modern.webp` | WebP support verified |
| **Vision extraction** | `images/faces-group-photo.jpg` | AI-generated description of scene |
| **PDF single page** | `documents/pdf-single-page.pdf` | Text extraction, whole chunking |
| **PDF multi-page** | `documents/pdf-multi-page.pdf` | Text extraction, per-section chunking |
| **Code syntactic chunking** | `documents/code-*.{py,rs,js,ts}` | Tree-sitter syntactic chunks |
| **Markdown semantic chunking** | `documents/markdown-formatted.md` | Semantic paragraph chunks |
| **JSON/YAML parsing** | `documents/*.{json,yaml}` | Structured data extraction |
| **Audio transcription (EN)** | `audio/english-speech-5s.mp3` | Speech-to-text transcription |
| **Audio transcription (ES)** | `audio/spanish-greeting.mp3` | Spanish transcription |
| **Audio transcription (ZH)** | `audio/chinese-phrase.mp3` | Chinese transcription |
| **FTS stemming (EN/DE/FR/ES/PT)** | `multilingual/{english,german,french,spanish,portuguese}.txt` | Stemmed search matches |
| **FTS bigram (CJK)** | `multilingual/{chinese,japanese,korean}.txt` | Character bigram matches |
| **FTS basic (AR/RU/EL/HE)** | `multilingual/{arabic,russian,greek,hebrew}.txt` | Basic tokenization |
| **Emoji/trigram search** | `multilingual/emoji-heavy.txt` | Trigram substring matches |
| **Empty file handling** | `edge-cases/empty.txt` | Graceful handling, warning |
| **Large file chunking** | `edge-cases/large-text-100kb.txt` | Appropriate chunking strategy |
| **Binary detection** | `edge-cases/binary-wrong-ext.jpg` | Error with clear message |
| **Unicode filenames** | `edge-cases/unicode-filename-ÊµãËØï.txt`, `images/emoji-unicode-ÂêçÂâç.jpg` | Correct storage |
| **Whitespace-only** | `edge-cases/whitespace-only.txt` | Empty content flag |
| **Malformed data** | `edge-cases/malformed-json.json` | Fallback to plain text |
| **GPS provenance** | `provenance/paris-*.jpg`, `provenance/newyork-*.jpg`, `provenance/tokyo-*.jpg` | Spatial provenance tracking |
| **Temporal provenance** | `provenance/dated-*.jpg` | Timestamp provenance tracking |
| **Content deduplication** | `provenance/duplicate-content-*.txt` | Same hash detected |

## Size Guidelines

To keep the repository lean:
- Images: Maximum 500KB each (compressed)
- Audio: Maximum 100KB each (5-10 seconds, compressed)
- Documents: Maximum 200KB each
- Total package: <10MB

For larger test files, use the download mechanism or generate synthetically.

## Dependencies

### Required Tools

- **Python 3.8+** (for generation scripts)
- **ffmpeg** (for audio generation)
- **ImageMagick** (for image manipulation)
- **exiftool** (for EXIF injection)

Install on Ubuntu/Debian:
```bash
sudo apt-get install python3 ffmpeg imagemagick exiftool python3-pip
pip3 install Pillow piexif faker gtts pydub
```

Install on macOS:
```bash
brew install python ffmpeg imagemagick exiftool
pip3 install Pillow piexif faker gtts pydub
```

## Maintenance

### Adding New Test Files

1. Add file to appropriate directory
2. Update `MANIFEST.md` with file specification
3. Update this README's coverage matrix
4. Add verification steps to test scenarios
5. Update generation scripts if synthetic

### Updating Existing Files

When updating test files:
1. Document changes in `MANIFEST.md`
2. Update expected results in test scenarios
3. Regenerate using scripts for consistency
4. Verify with integration tests

## References

- EXIF metadata extraction: `crates/matric-core/src/exif.rs`
- Document type registry: `migrations/20260202*_seed_*_document_types.sql`
- W3C PROV provenance: `crates/matric-db/src/provenance.rs`
- Multilingual FTS: `docs/content/search-capabilities.md`
- Document type detection: `crates/matric-core/src/models.rs`
